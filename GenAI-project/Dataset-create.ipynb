{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kZPVfgCSU1CM"
   },
   "outputs": [],
   "source": [
    "!rm -rf /content/drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13135,
     "status": "ok",
     "timestamp": 1762823069761,
     "user": {
      "displayName": "kevin mai",
      "userId": "13428005438010750061"
     },
     "user_tz": 360
    },
    "id": "J4xxtYfaU3oc",
    "outputId": "0ac3276f-fa89-4989-af7a-6e3321c5eedd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 650,
     "status": "ok",
     "timestamp": 1762703077692,
     "user": {
      "displayName": "kevin mai",
      "userId": "13428005438010750061"
     },
     "user_tz": 360
    },
    "id": "tR7ZHs36SiG4",
    "outputId": "d2a27013-7be6-4f95-cf87-0397bbaa610a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'gpt-2-output-dataset'...\n",
      "remote: Enumerating objects: 89, done.\u001b[K\n",
      "remote: Counting objects: 100% (10/10), done.\u001b[K\n",
      "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
      "remote: Total 89 (delta 8), reused 7 (delta 7), pack-reused 79 (from 2)\u001b[K\n",
      "Receiving objects: 100% (89/89), 272.84 KiB | 7.18 MiB/s, done.\n",
      "Resolving deltas: 100% (40/40), done.\n",
      "/content/gpt-2-output-dataset\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/openai/gpt-2-output-dataset.git\n",
    "%cd gpt-2-output-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 133261,
     "status": "ok",
     "timestamp": 1762705768543,
     "user": {
      "displayName": "kevin mai",
      "userId": "13428005438010750061"
     },
     "user_tz": 360
    },
    "id": "lni_t983Sm5m",
    "outputId": "7964d155-78de-4fda-b440-ab8905c5bdcd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/gpt-2-output-dataset\n",
      "Fetching webtext.train.jsonl: 679Mit [00:15, 44.3Mit/s]                                             \n",
      "Fetching webtext.valid.jsonl: 13.6Mit [00:00, 45.5Mit/s]                                            \n",
      "Fetching webtext.test.jsonl: 13.5Mit [00:00, 45.3Mit/s]                                             \n",
      "Fetching small-117M.train.jsonl: 775Mit [00:17, 45.5Mit/s]                                          \n",
      "Fetching small-117M.valid.jsonl: 15.4Mit [00:00, 46.1Mit/s]                                         \n",
      "Fetching small-117M.test.jsonl: 15.6Mit [00:00, 35.3Mit/s]                                          \n",
      "Fetching small-117M-k40.train.jsonl: 711Mit [00:12, 56.5Mit/s]                                      \n",
      "Fetching small-117M-k40.valid.jsonl: 14.4Mit [00:00, 41.2Mit/s]                                     \n",
      "Fetching small-117M-k40.test.jsonl: 14.4Mit [00:00, 42.3Mit/s]                                      \n",
      "Fetching medium-345M.train.jsonl: 791Mit [00:14, 56.1Mit/s]                                         \n",
      "Fetching medium-345M.valid.jsonl: 15.8Mit [00:00, 40.3Mit/s]                                        \n",
      "Fetching medium-345M.test.jsonl: 15.8Mit [00:00, 56.3Mit/s]                                         \n",
      "Fetching medium-345M-k40.train.jsonl: 784Mit [00:19, 40.1Mit/s]                                     \n",
      "Fetching medium-345M-k40.valid.jsonl: 15.7Mit [00:00, 71.2Mit/s]                                    \n",
      "Fetching medium-345M-k40.test.jsonl: 15.6Mit [00:00, 67.8Mit/s]                                     \n",
      "Fetching large-762M.train.jsonl: 753Mit [00:11, 63.8Mit/s]                                          \n",
      "Fetching large-762M.valid.jsonl: 14.9Mit [00:00, 68.7Mit/s]                                         \n",
      "Fetching large-762M.test.jsonl: 15.0Mit [00:00, 37.0Mit/s]                                          \n",
      "Fetching large-762M-k40.train.jsonl: 751Mit [00:12, 61.9Mit/s]                                      \n",
      "Fetching large-762M-k40.valid.jsonl: 15.0Mit [00:00, 73.6Mit/s]                                     \n",
      "Fetching large-762M-k40.test.jsonl: 15.0Mit [00:00, 66.9Mit/s]                                      \n",
      "Fetching xl-1542M.train.jsonl: 724Mit [00:09, 78.2Mit/s]                                            \n",
      "Fetching xl-1542M.valid.jsonl: 14.4Mit [00:00, 43.2Mit/s]                                           \n",
      "Fetching xl-1542M.test.jsonl: 14.6Mit [00:00, 49.1Mit/s]                                            \n",
      "Fetching xl-1542M-k40.train.jsonl: 748Mit [00:12, 59.7Mit/s]                                        \n",
      "Fetching xl-1542M-k40.valid.jsonl: 15.0Mit [00:00, 45.7Mit/s]                                       \n",
      "Fetching xl-1542M-k40.test.jsonl: 14.6Mit [00:00, 48.7Mit/s]                                        \n"
     ]
    }
   ],
   "source": [
    "%cd /content/gpt-2-output-dataset\n",
    "!python download_dataset.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8400,
     "status": "ok",
     "timestamp": 1762703741463,
     "user": {
      "displayName": "kevin mai",
      "userId": "13428005438010750061"
     },
     "user_tz": 360
    },
    "id": "Y0i2R9_QSp9C",
    "outputId": "f39bb704-5641-4917-b9b1-26289adf0001"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "The following NEW packages will be installed:\n",
      "  zstd\n",
      "0 upgraded, 1 newly installed, 0 to remove and 41 not upgraded.\n",
      "Need to get 603 kB of archives.\n",
      "After this operation, 1,695 kB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 zstd amd64 1.4.8+dfsg-3build1 [603 kB]\n",
      "Fetched 603 kB in 0s (3,039 kB/s)\n",
      "Selecting previously unselected package zstd.\n",
      "(Reading database ... 125082 files and directories currently installed.)\n",
      "Preparing to unpack .../zstd_1.4.8+dfsg-3build1_amd64.deb ...\n",
      "Unpacking zstd (1.4.8+dfsg-3build1) ...\n",
      "Setting up zstd (1.4.8+dfsg-3build1) ...\n",
      "Processing triggers for man-db (2.10.2-1) ...\n"
     ]
    }
   ],
   "source": [
    "!apt install -y zstd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 115,
     "status": "ok",
     "timestamp": 1762705874871,
     "user": {
      "displayName": "kevin mai",
      "userId": "13428005438010750061"
     },
     "user_tz": 360
    },
    "id": "pKgcN8utc_mk",
    "outputId": "b6d8d8fd-89ca-4838-9fee-922390be4343"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/gpt-2-output-dataset/data/large-762M-k40.test.jsonl\n",
      "/content/gpt-2-output-dataset/data/large-762M-k40.train.jsonl\n",
      "/content/gpt-2-output-dataset/data/large-762M-k40.valid.jsonl\n",
      "/content/gpt-2-output-dataset/data/large-762M.test.jsonl\n",
      "/content/gpt-2-output-dataset/data/large-762M.train.jsonl\n",
      "/content/gpt-2-output-dataset/data/large-762M.valid.jsonl\n",
      "/content/gpt-2-output-dataset/data/medium-345M-k40.test.jsonl\n",
      "/content/gpt-2-output-dataset/data/medium-345M-k40.train.jsonl\n",
      "/content/gpt-2-output-dataset/data/medium-345M-k40.valid.jsonl\n",
      "/content/gpt-2-output-dataset/data/medium-345M.test.jsonl\n",
      "/content/gpt-2-output-dataset/data/medium-345M.train.jsonl\n",
      "/content/gpt-2-output-dataset/data/medium-345M.valid.jsonl\n",
      "/content/gpt-2-output-dataset/data/small-117M-k40.test.jsonl\n",
      "/content/gpt-2-output-dataset/data/small-117M-k40.train.jsonl\n",
      "/content/gpt-2-output-dataset/data/small-117M-k40.valid.jsonl\n",
      "/content/gpt-2-output-dataset/data/small-117M.test.jsonl\n",
      "/content/gpt-2-output-dataset/data/small-117M.train.jsonl\n",
      "/content/gpt-2-output-dataset/data/small-117M.valid.jsonl\n",
      "/content/gpt-2-output-dataset/data/webtext.test.jsonl\n",
      "/content/gpt-2-output-dataset/data/webtext.train.jsonl\n",
      "/content/gpt-2-output-dataset/data/webtext.valid.jsonl\n",
      "/content/gpt-2-output-dataset/data/xl-1542M-k40.test.jsonl\n",
      "/content/gpt-2-output-dataset/data/xl-1542M-k40.train.jsonl\n",
      "/content/gpt-2-output-dataset/data/xl-1542M-k40.valid.jsonl\n",
      "/content/gpt-2-output-dataset/data/xl-1542M.test.jsonl\n",
      "/content/gpt-2-output-dataset/data/xl-1542M.train.jsonl\n",
      "/content/gpt-2-output-dataset/data/xl-1542M.valid.jsonl\n"
     ]
    }
   ],
   "source": [
    "!find /content/gpt-2-output-dataset -type f -name \"*.jsonl*\" | sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 107,
     "status": "ok",
     "timestamp": 1762706094891,
     "user": {
      "displayName": "kevin mai",
      "userId": "13428005438010750061"
     },
     "user_tz": 360
    },
    "id": "59HvjJWKdbGe",
    "outputId": "720356aa-c75d-4d78-e5ba-77477f2c498e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "large-762M-k40.test.jsonl    small-117M-k40.valid.jsonl\n",
      "large-762M-k40.train.jsonl   small-117M.test.jsonl\n",
      "large-762M-k40.valid.jsonl   small-117M.train.jsonl\n",
      "large-762M.test.jsonl\t     small-117M.valid.jsonl\n",
      "large-762M.train.jsonl\t     webtext.test.jsonl\n",
      "large-762M.valid.jsonl\t     webtext.train.jsonl\n",
      "medium-345M-k40.test.jsonl   webtext.valid.jsonl\n",
      "medium-345M-k40.train.jsonl  xl-1542M-k40.test.jsonl\n",
      "medium-345M-k40.valid.jsonl  xl-1542M-k40.train.jsonl\n",
      "medium-345M.test.jsonl\t     xl-1542M-k40.valid.jsonl\n",
      "medium-345M.train.jsonl      xl-1542M.test.jsonl\n",
      "medium-345M.valid.jsonl      xl-1542M.train.jsonl\n",
      "small-117M-k40.test.jsonl    xl-1542M.valid.jsonl\n",
      "small-117M-k40.train.jsonl\n"
     ]
    }
   ],
   "source": [
    "!ls /content/gpt-2-output-dataset/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8973,
     "status": "ok",
     "timestamp": 1762706149743,
     "user": {
      "displayName": "kevin mai",
      "userId": "13428005438010750061"
     },
     "user_tz": 360
    },
    "id": "zP6ugsBdeHpw",
    "outputId": "b5c4b157-c833-48f6-c213-4556027ced2e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GenAI-project.ipynb\t  xl-1542M-k40.valid.jsonl  xl-1542M.valid.jsonl\n",
      "xl-1542M-k40.test.jsonl   xl-1542M.test.jsonl\n",
      "xl-1542M-k40.train.jsonl  xl-1542M.train.jsonl\n"
     ]
    }
   ],
   "source": [
    "!cp /content/gpt-2-output-dataset/data/xl-1542M*.jsonl \"/content/drive/MyDrive/GenAI/\"\n",
    "!ls \"/content/drive/MyDrive/GenAI/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "haKyNAq3eS4S"
   },
   "outputs": [],
   "source": [
    "!mkdir -p \"/content/drive/MyDrive/GenAI/GPT2-data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A4wMK2p-e1mO"
   },
   "outputs": [],
   "source": [
    "!mv \"/content/drive/MyDrive/GenAI/xl-1542M\"*.jsonl \"/content/drive/MyDrive/GenAI/GPT2-data/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1762706304849,
     "user": {
      "displayName": "kevin mai",
      "userId": "13428005438010750061"
     },
     "user_tz": 360
    },
    "id": "u1TXQGMxe4Ap",
    "outputId": "54d8577d-8e21-483b-8b9f-4843a5f86831"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xl-1542M-k40.test.jsonl   xl-1542M-k40.valid.jsonl  xl-1542M.train.jsonl\n",
      "xl-1542M-k40.train.jsonl  xl-1542M.test.jsonl\t    xl-1542M.valid.jsonl\n"
     ]
    }
   ],
   "source": [
    "!ls \"/content/drive/MyDrive/GenAI/GPT2-data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5291,
     "status": "ok",
     "timestamp": 1762822998464,
     "user": {
      "displayName": "kevin mai",
      "userId": "13428005438010750061"
     },
     "user_tz": 360
    },
    "id": "4mor_eFJgPXd",
    "outputId": "8105259a-b461-4ddc-f095-0fb4e73d8431"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (1.109.1)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.11.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.11.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.11.10)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.15.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "## Gpt 3.5\n",
    "!pip install openai tqdm pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1762823178339,
     "user": {
      "displayName": "kevin mai",
      "userId": "13428005438010750061"
     },
     "user_tz": 360
    },
    "id": "zsDl291jgSs3"
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import json\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1762823212828,
     "user": {
      "displayName": "kevin mai",
      "userId": "13428005438010750061"
     },
     "user_tz": 360
    },
    "id": "lwj5_yHbgZeq"
   },
   "outputs": [],
   "source": [
    "API_KEY = \"\"  # Replace with your OpenAI API key\n",
    "MODEL_NAME = \"gpt-3.5-turbo\"\n",
    "SAVE_PATH = \"/content/drive/MyDrive/GenAI/GPT35-data/gpt35_outputs.csv\"\n",
    "PROMPT_FOLDER = \"/content/drive/MyDrive/GenAI/GPT2-data/\"\n",
    "N_SAMPLES = 2000\n",
    "MAX_TOKENS = 200\n",
    "TEMPERATURE = 0.7\n",
    "SAVE_EVERY = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 726,
     "status": "ok",
     "timestamp": 1762823084510,
     "user": {
      "displayName": "kevin mai",
      "userId": "13428005438010750061"
     },
     "user_tz": 360
    },
    "id": "uf6rzx-NgccI"
   },
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=API_KEY)\n",
    "os.makedirs(os.path.dirname(SAVE_PATH), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1284,
     "status": "ok",
     "timestamp": 1762823218359,
     "user": {
      "displayName": "kevin mai",
      "userId": "13428005438010750061"
     },
     "user_tz": 360
    },
    "id": "uu7RFE8RV7n3",
    "outputId": "61dd5147-8b2b-43cb-838d-98e33bb460c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 4974 raw prompts from 6 JSONL files\n"
     ]
    }
   ],
   "source": [
    "def load_prompts_from_jsonl(folder, n_samples):\n",
    "    files = glob.glob(os.path.join(folder, \"*.jsonl\"))\n",
    "    texts = []\n",
    "\n",
    "    for file in files:\n",
    "        with open(file, \"r\", encoding=\"utf-8\") as f:\n",
    "            for line in f:\n",
    "                try:\n",
    "                    data = json.loads(line)\n",
    "                    if \"text\" in data:\n",
    "                        t = data[\"text\"].strip()\n",
    "                        if len(t.split()) > 30:  # filter short texts\n",
    "                            texts.append(t)\n",
    "                except json.JSONDecodeError:\n",
    "                    continue\n",
    "        if len(texts) >= n_samples * 2:\n",
    "            break  # stop early if enough prompts collected\n",
    "\n",
    "    print(f\"Loaded {len(texts)} raw prompts from {len(files)} JSONL files\")\n",
    "    random.shuffle(texts)\n",
    "    return texts[:n_samples]\n",
    "\n",
    "prompts = load_prompts_from_jsonl(PROMPT_FOLDER, N_SAMPLES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1762823242530,
     "user": {
      "displayName": "kevin mai",
      "userId": "13428005438010750061"
     },
     "user_tz": 360
    },
    "id": "9Xo-TSzGcft8"
   },
   "outputs": [],
   "source": [
    "if os.path.exists(SAVE_PATH):\n",
    "    existing = pd.read_csv(SAVE_PATH)\n",
    "    outputs = existing.to_dict(\"records\")\n",
    "    start_idx = len(existing)\n",
    "    print(f\"Resuming from index {start_idx}\")\n",
    "else:\n",
    "    outputs = []\n",
    "    start_idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5306042,
     "status": "ok",
     "timestamp": 1762828561504,
     "user": {
      "displayName": "kevin mai",
      "userId": "13428005438010750061"
     },
     "user_tz": 360
    },
    "id": "2FG9QyuadAK4",
    "outputId": "e6a550df-6a09-402c-9b5b-a078976ce579"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting generation of 2000 GPT-3.5 samples...\n",
      "Generated 50/2000 samples...\n",
      "Generated 100/2000 samples...\n",
      "Generated 150/2000 samples...\n",
      "Generated 200/2000 samples...\n",
      "Generated 250/2000 samples...\n",
      "Generated 300/2000 samples...\n",
      "Generated 350/2000 samples...\n",
      "Generated 400/2000 samples...\n",
      "Generated 450/2000 samples...\n",
      "Generated 500/2000 samples...\n",
      "Generated 550/2000 samples...\n",
      "Generated 600/2000 samples...\n",
      "Generated 650/2000 samples...\n",
      "Generated 700/2000 samples...\n",
      "Generated 750/2000 samples...\n",
      "Generated 800/2000 samples...\n",
      "Generated 850/2000 samples...\n",
      "Generated 900/2000 samples...\n",
      "Generated 950/2000 samples...\n",
      "Generated 1000/2000 samples...\n",
      "Generated 1050/2000 samples...\n",
      "Generated 1100/2000 samples...\n",
      "Generated 1150/2000 samples...\n",
      "Generated 1200/2000 samples...\n",
      "Generated 1250/2000 samples...\n",
      "Generated 1300/2000 samples...\n",
      "Generated 1350/2000 samples...\n",
      "Generated 1400/2000 samples...\n",
      "Generated 1450/2000 samples...\n",
      "Generated 1500/2000 samples...\n",
      "Generated 1550/2000 samples...\n",
      "Generated 1600/2000 samples...\n",
      "Generated 1650/2000 samples...\n",
      "Generated 1700/2000 samples...\n",
      "Generated 1750/2000 samples...\n",
      "Generated 1800/2000 samples...\n",
      "Generated 1850/2000 samples...\n",
      "Generated 1900/2000 samples...\n",
      "Generated 1950/2000 samples...\n",
      "Generated 2000/2000 samples...\n"
     ]
    }
   ],
   "source": [
    "print(f\"Starting generation of {len(prompts)} GPT-3.5 samples...\")\n",
    "for i, p in enumerate(prompts[start_idx:], start=start_idx):\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=MODEL_NAME,\n",
    "            messages=[{\"role\": \"user\", \"content\": p[:200]}],\n",
    "            max_tokens=MAX_TOKENS,\n",
    "            temperature=TEMPERATURE,\n",
    "        )\n",
    "\n",
    "        text_out = response.choices[0].message.content.strip()\n",
    "        outputs.append(\n",
    "            {\n",
    "                \"text\": text_out,\n",
    "                \"label\": 1,\n",
    "                \"source_model\": MODEL_NAME,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        if (i + 1) % SAVE_EVERY == 0:\n",
    "            pd.DataFrame(outputs).to_csv(SAVE_PATH, index=False)\n",
    "            print(f\"Generated {i + 1}/{len(prompts)} samples...\")\n",
    "\n",
    "        time.sleep(random.uniform(0.5, 1.0))\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error at sample {i}: {e}\")\n",
    "        time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 83,
     "status": "ok",
     "timestamp": 1762828576880,
     "user": {
      "displayName": "kevin mai",
      "userId": "13428005438010750061"
     },
     "user_tz": 360
    },
    "id": "ix36ntaGdDVN",
    "outputId": "9d23b29f-a4ff-46da-b3b2-a010d77b1f10"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed. Saved 2000 rows to /content/drive/MyDrive/GenAI/GPT35-data/gpt35_outputs.csv\n"
     ]
    }
   ],
   "source": [
    "pd.DataFrame(outputs).to_csv(SAVE_PATH, index=False)\n",
    "print(f\"Completed. Saved {len(outputs)} rows to {SAVE_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1762829808809,
     "user": {
      "displayName": "kevin mai",
      "userId": "13428005438010750061"
     },
     "user_tz": 360
    },
    "id": "15IxiIGTexuu"
   },
   "outputs": [],
   "source": [
    "## gpt4\n",
    "MODEL_NAME = \"gpt-4-turbo\"\n",
    "SAVE_PATH = \"/content/drive/MyDrive/GenAI/GPT4-data/gpt4_outputs.csv\"\n",
    "N_SAMPLES = 2000\n",
    "MAX_TOKENS2 = 100\n",
    "TEMPERATURE = 0.7\n",
    "SAVE_EVERY = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1762829817364,
     "user": {
      "displayName": "kevin mai",
      "userId": "13428005438010750061"
     },
     "user_tz": 360
    },
    "id": "tA8lEAN2jM-n"
   },
   "outputs": [],
   "source": [
    "os.makedirs(os.path.dirname(SAVE_PATH), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 326,
     "status": "ok",
     "timestamp": 1762829818400,
     "user": {
      "displayName": "kevin mai",
      "userId": "13428005438010750061"
     },
     "user_tz": 360
    },
    "id": "cw8OlSL0jP9X",
    "outputId": "9b5fc481-bbbf-4512-c4b2-ab40e360586c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 4974 raw prompts from 6 JSONL files\n",
      "Resuming from index 100\n"
     ]
    }
   ],
   "source": [
    "prompts = load_prompts_from_jsonl(PROMPT_FOLDER, N_SAMPLES)\n",
    "\n",
    "if os.path.exists(SAVE_PATH):\n",
    "    existing = pd.read_csv(SAVE_PATH)\n",
    "    outputs = existing.to_dict(\"records\")\n",
    "    start_idx = len(existing)\n",
    "    print(f\"Resuming from index {start_idx}\")\n",
    "else:\n",
    "    outputs = []\n",
    "    start_idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9658680,
     "status": "ok",
     "timestamp": 1762839494449,
     "user": {
      "displayName": "kevin mai",
      "userId": "13428005438010750061"
     },
     "user_tz": 360
    },
    "id": "PYmlpxQPjYv8",
    "outputId": "31de154a-466e-4e72-b613-a4d0e089827d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting generation of 2000 GPT-4 samples...\n",
      "Generated 150/2000 samples...\n",
      "Generated 200/2000 samples...\n",
      "Generated 250/2000 samples...\n",
      "Generated 300/2000 samples...\n",
      "Generated 350/2000 samples...\n",
      "Generated 400/2000 samples...\n",
      "Generated 450/2000 samples...\n",
      "Generated 500/2000 samples...\n",
      "Generated 550/2000 samples...\n",
      "Generated 600/2000 samples...\n",
      "Generated 650/2000 samples...\n",
      "Generated 700/2000 samples...\n",
      "Generated 750/2000 samples...\n",
      "Generated 800/2000 samples...\n",
      "Generated 850/2000 samples...\n",
      "Generated 900/2000 samples...\n",
      "Generated 950/2000 samples...\n",
      "Generated 1000/2000 samples...\n",
      "Generated 1050/2000 samples...\n",
      "Generated 1100/2000 samples...\n",
      "Generated 1150/2000 samples...\n",
      "Generated 1200/2000 samples...\n",
      "Generated 1250/2000 samples...\n",
      "Generated 1300/2000 samples...\n",
      "Generated 1350/2000 samples...\n",
      "Generated 1400/2000 samples...\n",
      "Generated 1450/2000 samples...\n",
      "Generated 1500/2000 samples...\n",
      "Generated 1550/2000 samples...\n",
      "Generated 1600/2000 samples...\n",
      "Generated 1650/2000 samples...\n",
      "Generated 1700/2000 samples...\n",
      "Generated 1750/2000 samples...\n",
      "Generated 1800/2000 samples...\n",
      "Generated 1850/2000 samples...\n",
      "Generated 1900/2000 samples...\n",
      "Generated 1950/2000 samples...\n",
      "Generated 2000/2000 samples...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"Starting generation of {len(prompts)} GPT-4 samples...\")\n",
    "for i, p in enumerate(prompts[start_idx:], start=start_idx):\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=MODEL_NAME,\n",
    "            messages=[{\"role\": \"user\", \"content\": p[:200]}],\n",
    "            max_tokens=MAX_TOKENS2,\n",
    "            temperature=TEMPERATURE,\n",
    "        )\n",
    "\n",
    "        text_out = response.choices[0].message.content.strip()\n",
    "        outputs.append(\n",
    "            {\n",
    "                \"text\": text_out,\n",
    "                \"label\": 1,\n",
    "                \"source_model\": MODEL_NAME,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        if (i + 1) % SAVE_EVERY == 0:\n",
    "            pd.DataFrame(outputs).to_csv(SAVE_PATH, index=False)\n",
    "            print(f\"Generated {i + 1}/{len(prompts)} samples...\")\n",
    "\n",
    "        time.sleep(random.uniform(0.5, 1.0))\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error at sample {i}: {e}\")\n",
    "        time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 57,
     "status": "ok",
     "timestamp": 1762839838773,
     "user": {
      "displayName": "kevin mai",
      "userId": "13428005438010750061"
     },
     "user_tz": 360
    },
    "id": "XLwao5Y7jZvM",
    "outputId": "8f775b17-3a82-4297-fd2f-9ad14b77f0e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed. Saved 2000 rows to /content/drive/MyDrive/GenAI/GPT4-data/gpt4_outputs.csv\n"
     ]
    }
   ],
   "source": [
    "pd.DataFrame(outputs).to_csv(SAVE_PATH, index=False)\n",
    "print(f\"Completed. Saved {len(outputs)} rows to {SAVE_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 52212,
     "status": "ok",
     "timestamp": 1762839960335,
     "user": {
      "displayName": "kevin mai",
      "userId": "13428005438010750061"
     },
     "user_tz": 360
    },
    "id": "gfY_8daYjb1d",
    "outputId": "85c8bde8-1014-4a0b-fdf2-c8232a4af0e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/GenAI/GPT2-data\n",
      "--2025-11-11 05:45:08--  https://openaipublic.blob.core.windows.net/gpt-2/output-dataset/v1/webtext.train.jsonl\n",
      "Resolving openaipublic.blob.core.windows.net (openaipublic.blob.core.windows.net)... 20.60.244.1\n",
      "Connecting to openaipublic.blob.core.windows.net (openaipublic.blob.core.windows.net)|20.60.244.1|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 679129270 (648M) [application/octet-stream]\n",
      "Saving to: ‘webtext.train.jsonl’\n",
      "\n",
      "webtext.train.jsonl 100%[===================>] 647.67M  14.5MB/s    in 48s     \n",
      "\n",
      "2025-11-11 05:45:57 (13.4 MB/s) - ‘webtext.train.jsonl’ saved [679129270/679129270]\n",
      "\n",
      "--2025-11-11 05:45:57--  https://openaipublic.blob.core.windows.net/gpt-2/output-dataset/v1/webtext.valid.jsonl\n",
      "Resolving openaipublic.blob.core.windows.net (openaipublic.blob.core.windows.net)... 20.60.244.1\n",
      "Connecting to openaipublic.blob.core.windows.net (openaipublic.blob.core.windows.net)|20.60.244.1|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 13622302 (13M) [application/octet-stream]\n",
      "Saving to: ‘webtext.valid.jsonl’\n",
      "\n",
      "webtext.valid.jsonl 100%[===================>]  12.99M  10.4MB/s    in 1.3s    \n",
      "\n",
      "2025-11-11 05:45:59 (10.4 MB/s) - ‘webtext.valid.jsonl’ saved [13622302/13622302]\n",
      "\n",
      "--2025-11-11 05:45:59--  https://openaipublic.blob.core.windows.net/gpt-2/output-dataset/v1/webtext.test.jsonl\n",
      "Resolving openaipublic.blob.core.windows.net (openaipublic.blob.core.windows.net)... 20.60.244.1\n",
      "Connecting to openaipublic.blob.core.windows.net (openaipublic.blob.core.windows.net)|20.60.244.1|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 13478245 (13M) [application/octet-stream]\n",
      "Saving to: ‘webtext.test.jsonl’\n",
      "\n",
      "webtext.test.jsonl  100%[===================>]  12.85M  10.6MB/s    in 1.2s    \n",
      "\n",
      "2025-11-11 05:46:00 (10.6 MB/s) - ‘webtext.test.jsonl’ saved [13478245/13478245]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p /content/drive/MyDrive/GenAI/GPT2-data\n",
    "%cd /content/drive/MyDrive/GenAI/GPT2-data\n",
    "\n",
    "# Human-written data (Reddit WebText)\n",
    "!wget https://openaipublic.blob.core.windows.net/gpt-2/output-dataset/v1/webtext.train.jsonl\n",
    "!wget https://openaipublic.blob.core.windows.net/gpt-2/output-dataset/v1/webtext.valid.jsonl\n",
    "!wget https://openaipublic.blob.core.windows.net/gpt-2/output-dataset/v1/webtext.test.jsonl\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2538,
     "status": "ok",
     "timestamp": 1762840371395,
     "user": {
      "displayName": "kevin mai",
      "userId": "13428005438010750061"
     },
     "user_tz": 360
    },
    "id": "-eybDOf7eUNZ",
    "outputId": "c1aff4a2-c068-4287-db2c-797ec7ebcaa2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "webtext.train.jsonl           250,000 lines   (0.63 GB)\n",
      "webtext.valid.jsonl             5,000 lines   (0.01 GB)\n",
      "webtext.test.jsonl              5,000 lines   (0.01 GB)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "folder = \"/content/drive/MyDrive/GenAI/GPT2-data\"\n",
    "files = [\"webtext.train.jsonl\", \"webtext.valid.jsonl\", \"webtext.test.jsonl\"]\n",
    "\n",
    "for fname in files:\n",
    "    path = os.path.join(folder, fname)\n",
    "    if os.path.exists(path):\n",
    "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "            line_count = sum(1 for _ in f)\n",
    "        size_gb = os.path.getsize(path) / (1024**3)\n",
    "        print(f\"{fname:25}  {line_count:>10,} lines   ({size_gb:.2f} GB)\")\n",
    "    else:\n",
    "        print(f\"{fname:25}  not found\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOfX8D0Zbu/HXyorXSR0sfG",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
